# mysql logging mapping
mysql-error:
  source:
    '@type': tail
    path: '/var/log/mysql/error.log, /var/log/mysql/mysql-error.log, /var/log/mysqld.log'
    pos_file: '/var/log/td-agent/mysql-error.pos'
#    format: '/(?<time>[^ ]* [^ ]*)\s*\[(?<level>\S+)\]\s(?<message>.*)$/'
#    format: 'multi_format'
#    time_format: '%Y-%m-%d %H:%M:%S'
#    formats:
#     - '/(?<time>[^ ]* [^ ]*)\s*\[(?<level>\S+)\]\s(?<message>.*)$/'
#     - '/(?<time>[^ ]* [^ ]*)\s*(?<message>.*)$/'
  parse:
    '@type': multi_format
    expressions:
     - '/(?<time>[^ ]* [^ ]*)\s*\[(?<level>\S+)\]\s(?<message>.*)$/'
     - '/(?<time>[^ ]* [^ ]*)\s*(?<message>.*)$/'
  transform:
    node: '#{Socket.gethostname}'
    time: ${require 'time'; time.to_time.to_i}
    file: '${tag_suffix[1]}'
    _plugin: 'mysql'
    _documentType: 'mysqlErrorLogs'
    level: ${n_level='info'; if record.key?('level') == nil then n_level else record['level'].downcase end}
  match:
    flush_interval: 30s

mysql-general:
  source:
    '@type': tail
    path: '/var/log/mysql/mysql.log, /var/log/mysql.log'
    pos_file: '/var/log/td-agent/mysql-general-query.pos'
#    format: '/(?<time>[^ ]* [^ ]*)\s*(?<id>\S+)\s(?<command>[^ ]*)\s(?<argument>[^\t].*)$/'
#    format: 'multi_format'
#    formats:
#     - '/(?<time>[^ ]* [^ ]*)\s*(?<id>\S+)\s(?<command>[^ ]*)\s(?<argument>[^\t].*)$/'
#     - '/\"(?<time>[^\]]*)\"\W+(?<user1>\S+)\W+(?<user2>\w+)\W+(?<host>\w+)\W+(?<IP>(\d+\.\d+\.\d+\.\d+))\W+(?<pid1>\d+)\W+(?<pid2>\d+)\W+(?<command>.\w*)\W+(?<argument>.*)\"/'
#     - '/\"(?<time>[^\]]*)\"\W+(?<user1>\S+)\W+(?<user2>\w+)\W+(?<host>\w+)\W+(?<pid1>\d+)\W+(?<pid2>\d+)\W+(?<command>.\w*)\W+(?<argument>.*)\"/'
#     time_format: '%Y-%m-%d %H:%M:%S'
#     keep_time_key: 'true'
  parse:
    '@type': multi_format
    expressions:
     - '/(?<time>[^ ]* [^ ]*)\s*(?<id>\S+)\s(?<command>[^ ]*)\s(?<argument>[^\t].*)$/'
     - '/\"(?<time>[^\]]*)\"\W+(?<user1>\S+)\W+(?<user2>\w+)\W+(?<host>\w+)\W+(?<IP>(\d+\.\d+\.\d+\.\d+))\W+(?<pid1>\d+)\W+(?<pid2>\d+)\W+(?<command>.\w*)\W+(?<argument>.*)\"/'
     - '/\"(?<time>[^\]]*)\"\W+(?<user1>\S+)\W+(?<user2>\w+)\W+(?<host>\w+)\W+(?<pid1>\d+)\W+(?<pid2>\d+)\W+(?<command>.\w*)\W+(?<argument>.*)\"/'
  transform:
    node: '#{Socket.gethostname}'
    time: ${require 'time'; time.to_time.to_i}
    file: '${tag_suffix[1]}'
    _plugin: 'mysql'
    _documentType: 'mysqlAccessLogs'
    level: 'info'
    message: ''
  match:
    flush_interval: 30s

#mysql-slow:
#  source:
#    '@type': mysql_slow_query
#    path: '/var/log/mysql/mysql-slow.log'
#  filter:
#    node: '#{Socket.gethostname}'
#    time: ${require 'time'; time.to_time.to_f}
#    file: '${tag_suffix[1]}'
#    _plugin: 'mysql'
#    _documentType: 'slow-query'
#  match:
#    flush_interval: 30s

# apache logging mapping
apache-error:
   source:
     '@type': tail
#     format: apache_error
#     keep_time_key: 'true'
     path: '/var/log/apache2/error.log, /var/log/httpd/error_log'
     pos_file: '/var/log/td-agent/apache_error.pos'
   parse:
     '@type': apache_error
   transform:
     node: '#{Socket.gethostname}'
#       time: '#{Time.now.to_f}'
     file: '${tag_suffix[1]}'
     _plugin: 'apache'
     _documentType: 'apacheErrorLogs'
     time: ${require 'time'; time.to_time.to_i}
     component: ${record['level'].split(':').first()}
#     level: ${record['level'].split(':').last()}
     level: ${n_level='warning'; if record['level'].split(':').last().downcase == 'warn' then n_level else record['level'].split(':').last().downcase end}
   match:
     flush_interval: 30s
apache-access:
   source:
     '@type': tail
#     format: '/^(?<host>[^ ]*) [^ ]* (?<user>[^ ]*) \[(?<time>[^\]]*)\] "(?<method>\S+)(?: +(?<path>[^ ]*) +\S*)?" (?<code>[^ ]*) (?<size>[^ ]*)(?: "(?<referer>[^\"]*)" "(?<agent>[^\"]*)" (?<response_time>[^ ]*))?$/'
#     time_format: '%d/%b/%Y:%H:%M:%S %z'
#     keep_time_key: 'true'
     path: '/var/log/apache2/access.log, /var/log/httpd/access_log'
     pos_file: '/var/log/td-agent/apache_access.pos'
   parse:
     '@type': regexp
     time_format: '%d/%b/%Y:%H:%M:%S %z'
     expression: '^(?<host>[^ ]*(?:\s+[^ ]+)*) [\-](?<user>[\w\ ]*)[\-] \[(?<time>[^\]]*)\] "(?<method>\S+)(?: +(?<path>[^ ]*) +\S*)?" (?<code>[^ ]*) (?<size>[^ ]*)(?: "(?<referer>[^\"]*)" "(?<agent>[^\"]*)"(?:(| )(?<response_time>[^ ]*)))?$'
     types: 'response_time:integer, size:float'
   transform:
     node: '#{Socket.gethostname}'
#       time: '#{Time.now.to_f}'
     file: '${tag_suffix[1]}'
     _plugin: 'apache'
     _documentType: 'apacheAccessLogs'
     time: ${require 'time'; time.to_time.to_i}
     level: 'info'
     message: "${record['method'] + ' ' + record['path'] + ' ' + record['code']}"
   match:
     flush_interval: 30s

# libvirt log mapping
#libvirt:
#  source:
#    '@type': tail
#    path: '/var/log/libvirt/libvitd.log, /var/log/libvirt/*/*.log'
#    read_from_head: true
#    pos_file: '/var/log/td-agent/libvritd.pos'
#    refresh_interval: 2s
#  filter:
#    node: '#{Socket.gethostname}'
#    time: '#{Time.now.to_f}'
#    file: '${tag_suffix[1]}'
#  match:
#    flush_interval: 120s

# syslog mapping
linux-syslog:
  source:
    '@type': tail
    path: '/var/log/syslog, /var/log/auth.log, /var/log/messages, /var/log/secure'
    pos_file: '/var/log/td-agent/syslog.pos'
  rewrite_tag_filter:
#    tag: 'process'
 #   python: '(?<time>[^ ]*\s*[^ ]* [^ ]*) (?<host>[^ ]*) (?<ident>(python))'
    clear: '(?<time>[^ ]*\s*[^ ]* [^ ]*) (?<host>[^ ]*) (?<ident>(collectd)|(python))'
    extra_data: '(?<time>[^ ]*\s*[^ ]* [^ ]*) (?<host>[^ ]*) (?<ident>.*)'
  parse:
    extra_data:
     '@type': multi_format
     expressions:
      - '(?<time>[^ ]*\s*[^ ]* [^ ]*) (?<host>[^ ]*) (?<ident>[^:\[]*)(?:\[(?<pid>[0-9]+)\])?(?:[^\:]*\:)? \[(?<level>[^\]][\A-z]+)\] (?<message>.+)'
      - '(?<time>[^ ]*\s*[^ ]* [^ ]*) (?<host>[^ ]*) (?<ident>[^:\[]*)(?:\[(?<pid>[0-9]+)\])?(?:[^\:]*\:)? (?<level>(error)|(warning))\: (?<message>.*)'
      - '(?<time>[^ ]*\s*[^ ]* [^ ]*) (?<host>[^ ]*) (?<ident>[^:\[]*)(?:\[(?<pid>[0-9]+)\])?(?:[^\:]*\:)? (?<message>.*)'
  transform:
    node: '#{Socket.gethostname}'
    _plugin: 'linux'
    _documentType: 'syslog'
    file: '${tag_suffix[2]}'
    host: ${record['host']}
    ident: ${record['ident']}
    level: ${n_level='info'; if record.key?('level') == nil or record['level'] == nil then n_level else record['level'].strip() end}
    pid: ${record['pid']}
    time: ${require 'time'; time.to_time.to_i}
  match:
    flush_interval: 30s

default_flush_interval: 60s


nginx-error:
   source:
     '@type': tail
     format: nginx
     path: '/var/log/nginx/error.log'
     pos_file: '/var/log/td-agent/nginx_error.pos'
   parse:
     '@type': regexp
     time_format: '%Y/%m/%d %H:%M:%S'
     expression: '(?<time>[^ ]* [^ ]*)\s*\[(?<level>\S+)\]\s*(?<pid>\d+)#(?<tid>\d+)\:\s*(?<message>.*)$'
   transform:
     node: '#{Socket.gethostname}'
     file: '${tag_suffix[1]}'
     _plugin: 'nginx'
     _documentType: 'nginxErrorLogs'
     level: ${n_level='error'; if record['level'] == 'emerg' then n_level else record['level'] end}
     time: ${require 'time'; time.to_time.to_i}
   match:
     flush_interval: 30s

#NGINX access logging mapping
nginx-access:
  source:
    '@type': tail
    path: '/var/log/nginx/access.log'
    pos_file: '/var/log/td-agent/nginx_access.pos'
  parse:
    '@type': regexp
    time_format: '%d/%b/%Y:%H:%M:%S %z'
    #expression: '^(?<host>[^ ]*)\s-(?<user>[^-]*)-\s\[(?<time>[^\]]*)\]\s\"(?<method>[^ ]*)\s(?<path>[^"]*)\"\s(?<code>[^ ]*)\s(?<size>[^ ]*)\s\"(?<referer>[^"]*)\"\s\"(?<agent>[^"]*)\"\s\"(?<response_time>[^"]*)\"$'
    expression: '^(?<host>[^ ]*)\s(?<user>[^ ]*)\s\[(?<time>[^\]]*)\]\s\"(?<method>[^ ]*)\s(?<path>[^"]*)\"\s(?<code>[^ ]*)\s(?<size>[^ ]*)\s\"(?<referer>[^"]*)\"\s\"(?<agent>[^"]*)\"\s\"(?<referer2>[^"]*)\"\s(rt=(?<request_time>[^ ]*))\s(uct=(?<upstream_connect_time>[^ ]*))\s(uht=(?<upstream_header_time>[^ ]*))\s(urt=(?<upstream_response_time>[^ ]*))$'
  transform:
    node: '#{Socket.gethostname}'
    file: '${tag_suffix[1]}'
    _plugin: 'nginx'
    _documentType: 'nginxAccessLogs'
    time: ${require 'time'; time.to_time.to_i}
    level: 'info'
    message: "${record['method']+' '+record['path']+' '+record['code']}"
  match:
    flush_interval: 30s

#postgres logging mapping
postgres-general:
  source:
    '@type': tail
    path: '/var/lib/pgsql/9.6/data/pg_log/postgresql-Sun.log, /var/lib/pgsql/9.6/data/pg_log/postgresql-Sat.log, /var/lib/pgsql/9.6/data/pg_log/postgresql-Fri.log, /var/lib/pgsql/9.6/data/pg_log/postgresql-Thu.log, /var/lib/pgsql/9.6/data/pg_log/postgresql-Wed.log,  /var/lib/pgsql/9.6/data/pg_log/postgresql-Tue.log, /var/lib/pgsql/9.6/data/pg_log/postgresql-Mon.log, /var/log/postgresql/postgresql-10-main.log'
    pos_file: '/var/log/td-agent/postgres-general.pos'
  parse:
    '@type': regexp
    expression: '(?<time>[\0-9\a-z]+) (?<level>[\a-z]+\: ) (?<message>.*)'
  transform:
    node: '#{Socket.gethostname}'
    file: '${tag_suffix[1]}'
    _plugin: 'postgres'
    _documentType: 'postgresLogs'
    time: ${require 'time'; time.to_time.to_i}
    level: ${record['level'].split(':').first().downcase}
  match:
    flush_interval: 30s

# elasticserach logging mapping
elasticsearch-general:
  source:
    '@type': tail
    path: '/var/log/elasticsearch/master-master/es-cluster.log, /var/log/elasticsearch/node-0-node-0/es-cluster.log, /var/log/elasticsearch/node-1-node-1/es-cluster.log'
    pos_file: '/var/log/td-agent/elasticsearch.pos'
  multiline:
    format_firstline: '/^[\[]([^\]]*)[\]]/'
    expression:
      - '/^[\[](?<time>[^\]]*)[\]]\[(?<level>[^\]]*)\]\[(?<logging_class>[^\]]*)\] (?<message>[\s\S]*)/'
  transform:
    node: '#{Socket.gethostname}'
    file: '${tag_suffix[1]}'
    _plugin: 'elasticsearch'
    _documentType: 'ESLogs'
    time: ${require 'time'; time.to_time.to_i}
    logging_class: ${record['logging_class'].strip()}
   # level: ${record['level'].strip()}
    level: ${n_level='warning'; if record['level'].strip().downcase == 'warn' then n_level else record['level'].strip().downcase end}
    message: ${record['message']}
  match:
    flush_interval: 30s

# kafka logging mapping
kafka:
  source:
    '@type': tail
    path: '/opt/kafka/kafka_2.12-1.0.0/logs/server.log, /opt/kafka/kafka_2.12-1.0.0/logs/controller.log, /opt/kafka/kafka_2.12-1.0.0/logs/state-change.log'
    pos_file: '/var/log/td-agent/kafka.pos'
  multiline:
    format_firstline: '/^[\[]([^\]]*)[\]] ([^\ ]*)/'
    expression:
      - '/^[\[](?<time>[^\]]*)[\]] (?<level>[^\ ]*)(( \[(?<process>[^\ ]*)\ (?<process_id>[^\]]*)\])| )(?<message>.*)/'
  transform:
    node: '#{Socket.gethostname}'
    file: '${tag_suffix[1]}'
    _plugin: 'kafka'
    _documentType: 'kafkaLogs'
    time: ${require 'time'; time.to_time.to_i}
    level: ${n_level='warning'; if record['level'].downcase == 'warn' then n_level else record['level'].downcase end}
    process: ${record['process']}
    process_id: ${if record['process_id'] then record['process_id'].split('=')[1].split(' ')[0] else record['process_id'] end}
    message: ${record['message']}
  match:
    flush_interval: 30s

zookeeper:
  source:
    '@type': tail
    path: '/opt/kafka/kafka_2.12-1.0.0/logs/server.log, /opt/kafka/kafka_2.12-1.0.0/logs/controller.log, /opt/kafka/kafka_2.12-1.0.0/logs/state-change.log'
    pos_file: '/var/log/td-agent/zookeeper.pos'
  multiline:
    format_firstline: '/^[\[]([^\]]*)[\]] ([^\ ]*)/'
    expression:
      - '/^[\[](?<time>[^\]]*)[\]] (?<level>[^\ ]*)(( \[(?<process>[^\ ]*)\ (?<process_id>[^\]]*)\])| )(?<message>.*)/'
  transform:
    node: '#{Socket.gethostname}'
    file: '${tag_suffix[1]}'
    _plugin: 'zookeeper'
    _documentType: 'zookeeperLogs'
    time: ${require 'time'; time.to_time.to_i}
    level: ${n_level='warning'; if record['level'].downcase == 'warn' then n_level else record['level'].downcase end}
    process: ${record['process']}
    process_id: ${if record['process_id'] then record['process_id'].split('=')[1].split(' ')[0] else record['process_id'] end}
    message: ${record['message']}
  match:
    flush_interval: 30s

# Mapping for ESA collected log
esalogstore:
  esalogsdownload:
    '@type': exec
    format: tsv
    tag: ESALogsDownload
    command: python /opt/configurator-exporter/config_handler/mapping/esalogstore.py
    keys: ESALogsDownload
    run_interval: 10s
  source:
    '@type': tail
    path: '/var/log/esa_logs'
    pos_file: '/var/log/td-agent/esa.pos'
  parse:
    '@type': regexp
    expression: '(?<time>[\a-z]+\s[\a-z]+\s[\0-9\:]+) (?<level>\S+)\: (?<message>.*)'
  transform:
    file: '${tag_suffix[1]}'
    _plugin: 'esalogstore'
    _documentType: '${tag_suffix[6]}'
    time: ${require 'time'; time.to_time.to_i}
    level: ${record['level'].split(':').first().downcase}
    message: ${record['message']}
    _tag_uuid: "${tag_suffix[5].rpartition('_').last.split('.')[0]}"
    _tag_Name: "${tag_suffix[5].rpartition('_').first}"
  match:
    flush_interval: 30s

# Tomcat logger mapping
tomcat:
    source:
        '@type': tail
        path: '/opt/apache-tomcat-9.0.12/logs/catalina.out'
        pos_file: '/var/log/td-agent/tomcat.pos'
    multiline:
        format_firstline: '/^([^\:\ ]*)\s([^ ]*)\s([^\:\ ]*)\s\[([^\]]*)\]/'
        expression:
            - '/^(?<time>[^ ]*\s[^ ]*)\s(?<level>[^ ]*)\s\[(?<logging_class>[^ ]*)\]\s(?<class_name>[^ ]*)\s(?<message>.*)$/'
    transform:
        node: '#{Socket.gethostname}'
        file: '${tag_suffix[1]}'
        _plugin: 'tomcat'
        _documentType: 'tomcatLogs'
        time: ${require 'time'; time.to_time.to_i}
        level: ${n_level='warning'; if record['level'].strip().downcase == 'warn' then n_level else record['level'].strip().downcase end}
        message: ${record['message']}
    match:
        flush_interval: 30s
        
        # yarn resource manager logging mapping
yarn-rm:
  source:
    '@type': tail
    path: '/var/log/hadoop-yarn/yarn/yarn-yarn-resourcemanager-*.log'
    pos_file: '/var/log/td-agent/yarn-rm.pos'
  multiline:
    format_firstline: '/^(?<time>\d{4}-\d{2}-\d{2}\s+\d{2}:\d{2}:\d{2})\,[^ ]*[ ]*/'
    expression:
      - '/^(?<time>\d{4}-\d{2}-\d{2}\s+\d{2}:\d{2}:\d{2})\,[^ ]*[ ]*(?<level>[^ ]*) (?<message>[\s\S]*)/'
  transform:
    node: '#{Socket.gethostname}'
    file: '${tag_suffix[1]}'
    _plugin: 'hadoop-logs'
    _documentType: 'resourceManagerLog'
    time: ${require 'time'; time.to_time.to_i}
    level: ${n_level='warning'; if record['level'].strip().downcase == 'warn' then n_level else record['level'].strip().downcase end}
    message: ${record['message']}
  match:
    flush_interval: 30s

# yarn resource manager audit logging mapping
yarn-audit:
  source:
    '@type': tail
    path: '/var/log/hadoop-yarn/yarn/rm-audit.log'
    pos_file: '/var/log/td-agent/rm-audit.pos'
  multiline:
    format_firstline: '/^(?<time>\d{4}-\d{2}-\d{2}\s+\d{2}:\d{2}:\d{2})\,[^ ]*[ ]*/'
    expression:
      - '/^(?<time>\d{4}-\d{2}-\d{2}\s+\d{2}:\d{2}:\d{2})\,[^ ]*[ ]*(?<level>[^ ]*) (?<message>[\s\S]*)/'
  transform:
    node: '#{Socket.gethostname}'
    file: '${tag_suffix[1]}'
    _plugin: 'hadoop-logs'
    _documentType: 'yarnAuditLog'
    time: ${require 'time'; time.to_time.to_i}
    level: ${n_level='warning'; if record['level'].strip().downcase == 'warn' then n_level else record['level'].strip().downcase end}
    message: ${record['message']}
  match:
    flush_interval: 30s

#Yarn timeline server  logging mapping
yarn-timeline:
  source:
    '@type': tail
    path: '/var/log/hadoop-yarn/yarn/yarn-yarn-timelineserver-*.log'
    pos_file: '/var/log/td-agent/yarn-yarn-timelineserver.pos'
  multiline:
    format_firstline: '/^(?<time>\d{4}-\d{2}-\d{2}\s+\d{2}:\d{2}:\d{2})\,[^ ]*[ ]*/'
    expression:
      - '/^(?<time>\d{4}-\d{2}-\d{2}\s+\d{2}:\d{2}:\d{2})\,[^ ]*[ ]*(?<level>[^ ]*) (?<message>[\s\S]*)/'
  transform:
    node: '#{Socket.gethostname}'
    file: '${tag_suffix[1]}'
    _plugin: 'hadoop-logs'
    _documentType: 'timeLineServerLog'
    time: ${require 'time'; time.to_time.to_i}
    level: ${n_level='warning'; if record['level'].strip().downcase == 'warn' then n_level else record['level'].strip().downcase end}
    message: ${record['message']}
  match:
    flush_interval: 30s

# hdfs audit logging mapping
hdfs-audit:
  source:
    '@type': tail
    path: '/var/log/hadoop/hdfs/hdfs-audit.log'
    pos_file: '/var/log/td-agent/hdfs-audit.pos'
  parse:
    '@type': multi_format
    expressions:
     - '/^(?<time>\d{4}-\d{2}-\d{2}\s+\d{2}:\d{2}:\d{2})\,[^ ]*[ ]*(?<level>[^ ]*)\s+(?<message>.*)$/'
     - '/^(?<time>\d{4}-\d{2}-\d{2}\s+\d{2}:\d{2}:\d{2})\,[^ ]*[ ]*(?<level>[^ ]*)\s+(?<message>.*)/'
  transform:
    node: '#{Socket.gethostname}'
    file: '${tag_suffix[1]}'
    _plugin: 'hadoop-logs'
    _documentType: 'hdfsAuditLog'
    time: ${require 'time'; time.to_time.to_i}
    level: ${n_level='warning'; if record['level'].strip().downcase == 'warn' then n_level else record['level'].strip().downcase end}
    message: ${record['message']}
  match:
    flush_interval: 30s

# hdfs namenode logging mapping
hdfs-namenode:
  source:
    '@type': tail
    path: '/var/log/hadoop/hdfs/hadoop-hdfs-namenode-*.log'
    pos_file: '/var/log/td-agent/hadoop-hdfs-namenode.log.pos'
  multiline:
    format_firstline: '/^(?<time>\d{4}-\d{2}-\d{2}\s+\d{2}:\d{2}:\d{2})\,[^ ]*[ ]*/'
    expression:
      - '/^(?<time>\d{4}-\d{2}-\d{2}\s+\d{2}:\d{2}:\d{2})\,[^ ]*[ ]*(?<level>[^ ]*) (?<message>[\s\S]*)/'
  transform:
    node: '#{Socket.gethostname}'
    file: '${tag_suffix[1]}'
    _plugin: 'hadoop-logs'
    _documentType: 'nameNodeLog'
    time: ${require 'time'; time.to_time.to_i}
    level: ${n_level='warning'; if record['level'].strip().downcase == 'warn' then n_level else record['level'].strip().downcase end}
    message: ${record['message']}
  match:
    flush_interval: 30s


# oozie audit logging mapping
oozie-audit:
  source:
    '@type': tail
    path: '/var/log/oozie/oozie-audit.log'
    pos_file: '/var/log/td-agent/oozie-audit.log.pos'
  parse:
    '@type': regexp
    expression: '^(?<time>\d{4}-\d{2}-\d{2}\s+\d{2}:\d{2}:\d{2})\,[^ ]*[ ]*(?<level>[^ ]*)\s+(?<message>.*)'
  transform:
    node: '#{Socket.gethostname}'
    file: '${tag_suffix[1]}'
    _plugin: 'hadoop-logs'
    _documentType: 'oozieAuditLog'
    time: ${require 'time'; time.to_time.to_i}
    level: ${n_level='warning'; if record['level'].strip().downcase == 'warn' then n_level else record['level'].strip().downcase end}
    message: ${record['message']}
  match:
    flush_interval: 30s

# oozie Error logging mapping
oozie-error-logs:
  source:
    '@type': tail
    path: '/var/log/oozie/oozie-error.log'
    pos_file: '/var/log/td-agent/oozie-error.pos'
  parse:
    '@type': regexp
    expression: '^(?<time>\d{4}-\d{2}-\d{2}\s+\d{2}:\d{2}:\d{2})\,[^ ]*[ ]*(?<level>[^ ]*)\s+(?<message>.*)'
  transform:
    node: '#{Socket.gethostname}'
    file: '${tag_suffix[1]}'
    _plugin: 'hadoop-logs'
    _documentType: 'oozieErrorLog'
    time: ${require 'time'; time.to_time.to_i}
    level: ${n_level='warning'; if record['level'].strip().downcase == 'warn' then n_level else record['level'].strip().downcase end}
    message: ${record['message']}
  match:
    flush_interval: 30s

# oozie logging mapping
oozie-logs:
  source:
    '@type': tail
    path: '/var/log/oozie/oozie.log'
    pos_file: '/var/log/td-agent/oozie.pos'
  parse:
    '@type': regexp
    expression: '^(?<time>\d{4}-\d{2}-\d{2}\s+\d{2}:\d{2}:\d{2})\,[^ ]*[ ]*(?<level>[^ ]*)\s+(?<message>.*)'
  transform:
    node: '#{Socket.gethostname}'
    file: '${tag_suffix[1]}'
    _plugin: 'hadoop-logs'
    _documentType: 'oozieLog'
    time: ${require 'time'; time.to_time.to_i}
    level: ${n_level='warning'; if record['level'].strip().downcase == 'warn' then n_level else record['level'].strip().downcase end}
    message: ${record['message']}
  match:
    flush_interval: 30s

# yarn resource manager logging mapping
hdfs-journalnode-manager:
  source:
    '@type': tail
    path: '/var/log/hadoop/hdfs/hadoop-hdfs-journalnode-*.log'
    pos_file: '/var/log/td-agent/hadoop-hdfs-journalnode.log'
  multiline:
    format_firstline: '/^(?<time>\d{4}-\d{2}-\d{2}\s+\d{2}:\d{2}:\d{2})\,[^ ]*[ ]*/'
    expression:
      - '/^(?<time>\d{4}-\d{2}-\d{2}\s+\d{2}:\d{2}:\d{2})\,[^ ]*[ ]*(?<level>[^ ]*) (?<message>[\s\S]*)/'
  transform:
    node: '#{Socket.gethostname}'
    file: '${tag_suffix[1]}'
    _plugin: 'hadoop-logs'
    _documentType: 'journalNodeLog'
    time: ${require 'time'; time.to_time.to_i}
    level: ${n_level='warning'; if record['level'].strip().downcase == 'warn' then n_level else record['level'].strip().downcase end}
    message: ${record['message']}
  match:
    flush_interval: 30s

#hdfs zoopkeeper manager logs
hdfs-zkfc-manager:
  source:
    '@type': tail
    path: '/var/log/hadoop/hdfs/hadoop-hdfs-zkfc-*.log'
    pos_file: '/var/log/td-agent/hadoop-hdfs-zkfc.log'
  multiline:
    format_firstline: '/^(?<time>\d{4}-\d{2}-\d{2}\s+\d{2}:\d{2}:\d{2})\,[^ ]*[ ]*/'
    expression:
      - '/^(?<time>\d{4}-\d{2}-\d{2}\s+\d{2}:\d{2}:\d{2})\,[^ ]*[ ]*(?<level>[^ ]*) (?<message>[\s\S]*)/'
  transform:
    node: '#{Socket.gethostname}'
    file: '${tag_suffix[1]}'
    _plugin: 'hadoop-logs'
    _documentType: 'hdfsZkfcLog'
    time: ${require 'time'; time.to_time.to_i}
    level: ${n_level='warning'; if record['level'].strip().downcase == 'warn' then n_level else record['level'].strip().downcase end}
    message: ${record['message']}
  match:
    flush_interval: 30s

#Oozie jpa logs
oozie-jpa:
  source:
    '@type': tail
    path: '/var/log/oozie/oozie-jpa.log'
    pos_file: '/var/log/td-agent/oozie-jpa.log.pos'
  multiline:
    format_firstline: '/^(?<time>\d{4}-\d{2}-\d{2}\s+\d{2}:\d{2}:\d{2})\,[^ ]*[ ]*/'
    expression:
      - '/^(?<time>\d{4}-\d{2}-\d{2}\s+\d{2}:\d{2}:\d{2})\,[^ ]*[ ]*(?<level>[^ ]*) (?<message>[\s\S]*)/'
  transform:
    node: '#{Socket.gethostname}'
    file: '${tag_suffix[1]}'
    _plugin: 'hadoop-logs'
    _documentType: 'oozieJpaLog'
    time: ${require 'time'; time.to_time.to_i}
    level: ${n_level='warning'; if record['level'].strip().downcase == 'warn' then n_level else record['level'].strip().downcase end}
    message: ${record['message']}
  match:
    flush_interval: 30s

#Oozie instrumentation logs
oozie-instrumentation:
  source:
    '@type': tail
    path: '/var/log/oozie/oozie-instrumentation.log'
    pos_file: '/var/log/td-agent/oozie-instrumentation.log.pos'
  multiline:
    format_firstline: '/^(?<time>\d{4}-\d{2}-\d{2}\s+\d{2}:\d{2}:\d{2})\,[^ ]*[ ]*/'
    expression:
      - '/^(?<time>\d{4}-\d{2}-\d{2}\s+\d{2}:\d{2}:\d{2})\,[^ ]*[ ]*(?<level>[^ ]*) (?<message>[\s\S]*)/'
  transform:
    node: '#{Socket.gethostname}'
    file: '${tag_suffix[1]}'
    _plugin: 'hadoop-logs'
    _documentType: 'oozieInstrumentationLog'
    time: ${require 'time'; time.to_time.to_i}
    level: ${n_level='warning'; if record['level'].strip().downcase == 'warn' then n_level else record['level'].strip().downcase end}
    message: ${record['message']}
  match:
    flush_interval: 30s

#Oozie ops logs
oozie-ops:
  source:
    '@type': tail
    path: '/var/log/oozie/oozie-ops.log'
    pos_file: '/var/log/td-agent/oozie-ops.log.pos'
  multiline:
    format_firstline: '/^(?<time>\d{4}-\d{2}-\d{2}\s+\d{2}:\d{2}:\d{2})\,[^ ]*[ ]*/'
    expression:
      - '/^(?<time>\d{4}-\d{2}-\d{2}\s+\d{2}:\d{2}:\d{2})\,[^ ]*[ ]*(?<level>[^ ]*) (?<message>[\s\S]*)/'
  transform:
    node: '#{Socket.gethostname}'
    file: '${tag_suffix[1]}'
    _plugin: 'hadoop-logs'
    _documentType: 'oozieOpsLog'
    time: ${require 'time'; time.to_time.to_i}
    level: ${n_level='warning'; if record['level'].strip().downcase == 'warn' then n_level else record['level'].strip().downcase end}
    message: ${record['message']}
  match:
    flush_interval: 30s

hdfs-datanode:
  source:
    '@type': tail
    path: '/var/log/hadoop/hdfs/hadoop-hdfs-datanode-*.log'
    pos_file: '/var/log/td-agent/hadoop-hdfs-datanode.pos'
  multiline:
    format_firstline: '/^(?<time>\d{4}-\d{2}-\d{2}\s+\d{2}:\d{2}:\d{2})\,[^ ]*[ ]*/'
    expression:
      - '/^(?<time>\d{4}-\d{2}-\d{2}\s+\d{2}:\d{2}:\d{2})\,[^ ]*[ ]*(?<level>[^ ]*) (?<message>[\s\S]*)/'
  transform:
    node: '#{Socket.gethostname}'
    file: '${tag_suffix[1]}'
    _plugin: 'hadoop-logs'
    _documentType: 'dataNodeLog'
    time: ${require 'time'; time.to_time.to_i}
    level: ${n_level='warning'; if record['level'].strip().downcase == 'warn' then n_level else record['level'].strip().downcase end}
    message: ${record['message']}
  match:
    flush_interval: 30s
